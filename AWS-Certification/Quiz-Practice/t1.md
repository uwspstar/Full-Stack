### Authentication:
- A principal sending a request must be authenticated to send a request to AWS.
- To authenticate from the ```console```, you must sign in with your ```user name and password```.
- To authenticate from the ```API or CLI```, you must provide your ``access key and secret key```.

### An application you manage stores encrypted data in S3 buckets. You need to be able to query the encrypted data using SQL queries and write the encrypted results back the S3 bucket. As the data is sensitive you need to implement fine-grained control over access to the S3 bucket.What combination of services represent the BEST options support these requirements? (choose 2)

- Use IAM policies to restrict access to the bucket   (Correct)
- Use bucket ACLs to restrict access to the bucket   
- Use the AWS KMS API to query the encrypted data, and the S3 API for writing the results   
- Use Athena for querying the data and writing the results back to the bucket   (Correct)
- Use AWS Glue to extract the data, analyze it, and load it back to the S3 bucket   
```
Athena also allows you to easily query encrypted data stored in Amazon S3 and write encrypted results back to your S3 bucket. Both, server-side encryption and client-side encryption are supported
With IAM policies, you can grant IAM users fine-grained control to your S3 buckets, and is preferable to using bucket ACLs
AWS Glue is an ETL service and is not used for querying and analyzing data in S3
The AWS KMS API can be used for encryption purposes, however it cannot perform analytics so is not suitable
```

### A research company is developing a data lake solution in Amazon S3 to analyze huge datasets. The solution makes infrequent SQL queries only. In addition, the company wants to ```minimize infrastructure costs.```

Which AWS service should be used to meet these requirements?
```
 Amazon Athena
 Amazon Redshift Spectrum
 Amazon RDS for MySQL
 Amazon Aurora
```
### A manufacturing company captures data from machines running at customer sites. Currently, thousands of machines send data every 5 minutes, and this is expected to grow to hundreds of thousands of machines in the near future. The data is logged with the intent to be analyzed in the future as needed. What is the SIMPLEST method to store this streaming data at scale?
- Create an Amazon EC2 instance farm behind an ELB to store the data in Amazon EBS Cold HDD volumes
- Create an Amazon SQS queue, and have the machines write to the queue
- Create an Amazon Kinesis Firehose delivery stream to store the data in Amazon S3 (Correct)
- Create an Auto Scaling Group of Amazon EC2 instances behind ELBs to write data into Amazon RDS
```
Kinesis Data Firehose is the easiest way to load streaming data into data stores and analytics tools. 
It captures, transforms, and loads streaming data 
and you can deliver the data to “destinations” including Amazon S3 buckets for later analysis

Writing data into RDS via a series of EC2 instances and a load balancer is more complex and more expensive. 
RDS is also not an ideal data store for this data

Using an SQS queue to store the data is not possible 
as the data needs to be stored long-term 
and SQS queues have a maximum retention time of 14 days

Storing the data in EBS wold be expensive 
and as EBS volumes cannot be shared by multiple instances 
you would have a bottleneck of a single EC2 instance writing the data
```
### A Solutions Architect is deploying an ```Auto Scaling Group (ASG)``` and needs to determine what CloudWatch monitoring option to use. Which of the statements below would assist the Architect in making his decision? (choose 2) ```2,5```  
- Detailed monitoring is free and can be manually enabled   
- Detailed monitoring is enabled by default if the ASG is created from the CLI   
- Basic monitoring is enabled by default if the ASG is created from the CLI   
- Detailed monitoring is chargeable and must always be manually enabled   
- Basic monitoring is enabled by default if the ASG is created from the console   
```
Basic monitoring sends EC2 metrics to CloudWatch about ASG instances every 5 minutes
Detailed can be enabled and sends metrics every 1 minute (it is always chargeable)
When the launch configuration is created from the CLI 
detailed monitoring of EC2 instances is enabled by default
When you enable Auto Scaling group metrics, 
Auto Scaling sends sampled data to CloudWatch every minute
```
